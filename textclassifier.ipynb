{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-31 11:04:37.185289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","import torch.optim as optim\n","from transformers import get_linear_schedule_with_warmup\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["data = pd.read_csv('/workspace/nlplab/nmquy/pytorch/full_train.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>RevId</th>\n","      <th>UserId</th>\n","      <th>Comment</th>\n","      <th>image_urls</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3839333</td>\n","      <td>10106093.0</td>\n","      <td>Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...</td>\n","      <td>['https://images.foody.vn/res/g97/966781/s800/...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2824877</td>\n","      <td>786914.0</td>\n","      <td>Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...</td>\n","      <td>['https://images.foody.vn/res/g69/688413/s800/...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>9816702</td>\n","      <td>22467889.0</td>\n","      <td>Thời tiết lạnh như này, cả nhà rủ nhau đến leg...</td>\n","      <td>['https://images.foody.vn/res/g72/715078/s800/...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2684585</td>\n","      <td>1889449.0</td>\n","      <td>Em có đọc review thấy mng bảo trà sữa nướng đề...</td>\n","      <td>['https://images.foody.vn/res/g90/895545/s800/...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2737987</td>\n","      <td>8839942.0</td>\n","      <td>Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...</td>\n","      <td>['https://images.foody.vn/res/g4/30186/s800/fo...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Unnamed: 0    RevId      UserId  \\\n","0          0  3839333  10106093.0   \n","1          1  2824877    786914.0   \n","2          2  9816702  22467889.0   \n","3          3  2684585   1889449.0   \n","4          4  2737987   8839942.0   \n","\n","                                             Comment  \\\n","0  Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...   \n","1  Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...   \n","2  Thời tiết lạnh như này, cả nhà rủ nhau đến leg...   \n","3  Em có đọc review thấy mng bảo trà sữa nướng đề...   \n","4  Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...   \n","\n","                                          image_urls  Rating  \n","0  ['https://images.foody.vn/res/g97/966781/s800/...     1.0  \n","1  ['https://images.foody.vn/res/g69/688413/s800/...     0.0  \n","2  ['https://images.foody.vn/res/g72/715078/s800/...     1.0  \n","3  ['https://images.foody.vn/res/g90/895545/s800/...     0.0  \n","4  ['https://images.foody.vn/res/g4/30186/s800/fo...     1.0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["9073"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(data)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["data = data.dropna()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["9070"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(data)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["data_review = data['Comment'].tolist()\n","data_label = data['Rating'].astype(int).tolist()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["'Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trông rất thích'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data_review[0]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data_label[0]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["9070"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(data_review)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["9070"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["len(data_label)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["64001"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["len(tokenizer.get_vocab())"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["combined_data = list(zip(data_review, data_label))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["random.shuffle(combined_data)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["train_data, label = zip(*combined_data)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import re"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from underthesea import word_tokenize, text_normalize"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def clean_data(sent):\n","    vietnamese_characters = \"a-zA-Z0-9ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯĂẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂẾưăạảấầẩẫậắằẳẵặẹẻẽềềểếỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲỴÝỶỸửữựỳýỵỷỹ\"\n","    sent = sent.lower()\n","    sent = sent.strip()\n","    sent = re.sub('[+]', ' ', sent)\n","    sent = re.sub(\" \\\\[a-z]\" , ' ', sent)\n","    sent = re.sub('[^' + vietnamese_characters + ']' , ' ', sent)\n","    sent = re.sub(\"([A-Za-z]+[0-9]+)|([0-9]+[A-Za-z]+)\", \" \",sent)\n","    sent = re.sub(\"[0-9]{3,}\", \" \", sent)\n","    sent = re.sub(r'(\\D)\\1{2,}', r'\\1',sent)\n","    sent = sent.strip()\n","\n","    sent_temp = []\n","    for x in sent.split(\" \"):\n","        if len(x) > 1:\n","            sent_temp.append(x)\n","    sent = \" \".join(sent_temp)\n","    sent = text_normalize(sent)\n","\n","    return sent\n","\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def preprocess(sentences, max_len=None):\n","    preprocess_sent = []\n","\n","    for sent in sentences:\n","        text = word_tokenize(sent, format=\"text\")\n","        new_sent = text\n","        if max_len is not None:\n","            words = text.split(\" \")\n","            if len(words) > max_len:\n","                words = words[0:max_len]\n","            new_sent = \" \".join(words)\n","        preprocess_sent.append(new_sent)\n","\n","    return preprocess_sent\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def encode(preprocess_sent, max_len=128):\n","    encode_sents = []\n","    masks = []\n","\n","    for sent in preprocess_sent:\n","        sent_info = tokenizer.encode_plus(\n","            sent,\n","            padding=\"max_length\",\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=max_len,\n","            return_token_type_ids=False,\n","            return_attention_mask=True,\n","            return_tensors='np'\n","        )\n","        encode_sent = sent_info['input_ids'].flatten()\n","        mask = sent_info['attention_mask'].flatten()\n","\n","        encode_sents.append(encode_sent)\n","        masks.append(mask)\n","\n","    return encode_sents, masks"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["data_train = train_data[0:7000]\n","label_train = label[0:7000]\n","data_valid = train_data[7001:]\n","label_valid = label[7001:]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mình vừa đặt ship đồ về nhà ăn, mặc dù thời gian chờ now ship lâu vãi chưởng ))) nhưng chất lượng đồ ăn thì toẹt vờiii, kimchi cũng ngon nứaaaa, sẽ ủng hộ dại\n","0\n"]}],"source":["print(data_train[0])\n","print(label[0])"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["train_data_clean = [clean_data(sent) for sent in data_train]\n","data_valid = [clean_data(sent) for sent in data_valid]"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["train_data_preprocess = preprocess(train_data_clean)\n","valid_data_preprocess = preprocess(data_valid)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["train_ids, train_mask = encode(train_data_preprocess, max_len=256)\n","valid_ids, valid_mask = encode(valid_data_preprocess, max_len=256)\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["batch_size = 8"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_28938/1249001402.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  train_mask = torch.tensor(train_mask)\n","/tmp/ipykernel_28938/1249001402.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  valid_mask = torch.tensor(valid_mask)\n"]}],"source":["train_input = torch.tensor(train_ids)\n","valid_input = torch.tensor(valid_ids)\n","\n","train_label = torch.tensor(label_train)\n","valid_label = torch.tensor(label_valid)\n","\n","train_mask = torch.tensor(train_mask)\n","valid_mask = torch.tensor(valid_mask)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["train_data = TensorDataset(train_input, train_mask, train_label)\n","train_sample = RandomSampler(train_data)\n","train_loader = DataLoader(train_data, sampler=train_sample, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["valid_data = TensorDataset(valid_input, valid_mask, valid_label)\n","valid_sample = RandomSampler(valid_data)\n","valid_loader = DataLoader(valid_data, sampler=valid_sample, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["class Model_Sentiment(nn.Module):\n","    def __init__(self, output_size=2, dropout=0.1):\n","        super(Model_Sentiment, self).__init__()\n","        self.output_size = output_size\n","        self.dropout = dropout\n","        self.bert =  AutoModel.from_pretrained(\"vinai/phobert-base\", num_labels=2, output_hidden_states=True)\n","        self.fc2 = nn.Linear(4*768, self.output_size, bias=True)\n","        nn.init.normal_(self.fc2.weight, std=0.02)\n","        nn.init.normal_(self.fc2.bias, 0)\n","    \n","    def forward(self, inputs, attention_mask):\n","        outputs = self.bert(input_ids=inputs, attention_mask=attention_mask)\n","        x = torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1)\n","        x = self.fc2(x)\n","        out = x\n","        return out\n","        \n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model_sentiment = Model_Sentiment()"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["201\n"]}],"source":["count = 0\n","for param in model_sentiment.parameters():\n","    if param.requires_grad == True:\n","        count += 1\n","\n","print(count)\n"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["cnt = 0\n","for param in model_sentiment.parameters():\n","    if cnt < 100:\n","        param.requires_grad = False\n","    cnt += 1\n"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["101\n"]}],"source":["count = 0\n","for param in model_sentiment.parameters():\n","    if param.requires_grad == True:\n","        count += 1\n","\n","print(count)"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["max_epochs = 10\n","lr = 1e-4\n","weight_decay = 0.01\n","optimizer_parameter = filter(lambda p : p.requires_grad, model_sentiment.parameters())\n"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(\n","    optimizer_parameter,\n","    lr = lr,\n","    weight_decay=weight_decay\n",")\n","lr_scheduler = get_linear_schedule_with_warmup(\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=len(train_loader) * max_epochs\n",")"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":["def flatten_accuracy(pred, label):\n","    pred_flat = np.argmax(pred, axis = 1).flatten()\n","    label_flat = label.flatten()\n","    return np.sum(pred_flat == label_flat) / len(label_flat)"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"data":{"text/plain":["Model_Sentiment(\n","  (bert): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n","      (position_embeddings): Embedding(258, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc2): Linear(in_features=3072, out_features=2, bias=True)\n",")"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["model_sentiment.to(device=device)"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/875 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["input =  tensor([[    0,    68,  3310,  ...,     1,     1,     1],\n","        [    0,  1340,   136,  ...,     1,     1,     1],\n","        [    0,   654,   898,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  1953,    10,  ...,     1,     1,     1],\n","        [    0,  1338,   734,  ...,     1,     1,     1],\n","        [    0,    68, 49833,  ...,     1,     1,     1]])\n","input_mask =  tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])\n","label =  tensor([1, 0, 1, 1, 1, 1, 1, 1])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for batch in tqdm(train_loader):\n","    input, input_mask, label = batch\n","    print(\"input = \",input)\n","    print(\"input_mask = \",input_mask)\n","    print(\"label = \",label)\n","    break"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/259 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["input =  tensor([[    0,   946, 11941,  ...,     1,     1,     1],\n","        [    0, 23257,  1325,  ...,     1,     1,     1],\n","        [    0,   946,   170,  ...,     1,     1,     1],\n","        ...,\n","        [    0,   320,    89,  ...,     1,     1,     1],\n","        [    0,   244,  5516,  ...,     1,     1,     1],\n","        [    0,    68,   320,  ...,     1,     1,     1]])\n","input_mask =  tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])\n","label =  tensor([1, 1, 1, 1, 1, 0, 1, 0])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for batch in tqdm(valid_loader):\n","    input, input_mask, label = batch\n","    print(\"input = \",input)\n","    print(\"input_mask = \",input_mask)\n","    print(\"label = \",label)\n","    break"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["def train_epochs(model, criterion, optimizer, scheduler, train_loader, device):\n","    total_loss = 0\n","    total_acc = 0\n","    total = 0\n","    temp = 0\n","    model.train()\n","\n","    for batch in tqdm(train_loader):\n","        input, input_mask, label = batch\n","        input = input.to(device=device)\n","        input_mask = input_mask.to(device=device)\n","        label = label.to(device=device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(input, input_mask)\n","\n","        loss = criterion(output, label)\n","        loss.backward()\n","\n","        nn.utils.clip_grad_norm_(optimizer_parameter, max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","\n","        total_loss += loss.item()\n","        total += len(label)\n","\n","        logits = output.detach().cpu().numpy()\n","        label = label.to('cpu').numpy()\n","        acc = flatten_accuracy(logits, label)\n","        total_acc += acc\n","\n","        temp += 1\n","\n","    return total_loss/ total , total_acc/ temp\n","\n"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["def valid_epochs(model, criterion, valid_loader, device):\n","    total_loss = 0\n","    accuracy = 0\n","    temp = 0\n","    total = 0\n","    model.eval()\n","\n","    for batch in tqdm(valid_loader):\n","        input, input_mask, label = batch\n","        input = input.to(device=device)\n","        input_mask = input_mask.to(device=device)\n","        label = label.to(device=device)\n","\n","        with torch.no_grad():\n","            logit = model(input, input_mask)\n","            loss = criterion(logit, label)\n","\n","            logit = logit.detach().cpu().numpy()\n","            label = label.to('cpu').numpy()\n","\n","            acc = flatten_accuracy(logit, label)\n","            accuracy += acc\n","            total_loss += loss.item()\n","            total += len(label)\n","            temp += 1\n","    return total_loss / total, accuracy/ temp\n"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 875/875 [01:59<00:00,  7.33it/s]\n","100%|██████████| 259/259 [00:18<00:00, 14.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs 0 : Train accuracy = 0.7871428571428571,  Loss = 0.06522452805723462\n","Epochs 0 : Valid accuracy = 0.78996138996139,  Loss = 0.0650539448175988\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 875/875 [02:00<00:00,  7.27it/s]\n","100%|██████████| 259/259 [00:19<00:00, 13.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs 1 : Train accuracy = 0.7871428571428571,  Loss = 0.06500148065601076\n","Epochs 1 : Valid accuracy = 0.7905405405405406,  Loss = 0.06516893101435689\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 875/875 [02:00<00:00,  7.23it/s]\n","100%|██████████| 259/259 [00:19<00:00, 13.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs 2 : Train accuracy = 0.7871428571428571,  Loss = 0.0650347018284457\n","Epochs 2 : Valid accuracy = 0.7905405405405406,  Loss = 0.06490124481896262\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 875/875 [02:01<00:00,  7.21it/s]\n","100%|██████████| 259/259 [00:19<00:00, 13.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs 3 : Train accuracy = 0.787,  Loss = 0.06503199277605329\n","Epochs 3 : Valid accuracy = 0.7902509652509653,  Loss = 0.06440309995093053\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 875/875 [02:01<00:00,  7.18it/s]\n","100%|██████████| 259/259 [00:19<00:00, 13.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Epochs 4 : Train accuracy = 0.7871428571428571,  Loss = 0.06487974854239395\n","Epochs 4 : Valid accuracy = 0.7902509652509653,  Loss = 0.06495863707702824\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["epochs = 5\n","n_epochs = 0\n","train_loss = []\n","train_acc = []\n","valid_loss = []\n","valid_acc = []\n","\n","for _ in range(epochs):\n","    loss, acc = train_epochs(model = model_sentiment, criterion=criterion, optimizer=optimizer, scheduler=lr_scheduler, train_loader=train_loader, device=device)\n","    val_loss, val_acc = valid_epochs(model = model_sentiment, criterion=criterion, valid_loader=valid_loader, device=device)\n","    train_loss.append(loss)\n","    train_acc.append(acc)\n","    valid_acc.append(val_acc)\n","    valid_loss.append(val_loss)\n","\n","    print(f'Epochs {_} : Train accuracy = {acc},  Loss = {loss}')\n","    print(f'Epochs {_} : Valid accuracy = {val_acc},  Loss = {val_loss}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
